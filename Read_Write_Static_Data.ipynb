{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe56aa3-6a35-4369-a670-3c68f2d9a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560ff84b-2b79-47a5-a7f1-d1e9ed1354fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e72e2bd6-ce4e-4780-985d-45c778cf184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db5ae54-bc65-46e7-989b-1020b9ea6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(\"/opt/manual/spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa73dc1-64b6-4b82-8bb8-7fce3bea186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/manual/spark-3.1.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "2022-11-23 02:28:41,618 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "                    .config(\"spark.sql.shuffle.partitions\", 5)\n",
    "                    .config(\"spark.driver.memory\", \"16g\")\n",
    "                    .master(\"local[4]\")\n",
    "                    .appName(\"Pre_Proccessing_refined\")\n",
    "                    .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e080d8-946b-416d-987c-8c29e49ea56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"/home/train/datasets/sensor_raw_dataset/KETI/\"\n",
    "\n",
    "file_path_list = []\n",
    "directory_names = []\n",
    "names=[]\n",
    "dirpaths=[]\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(rootdir):#topdown incelenecek...\n",
    "    numbers=range(len(filenames))\n",
    "    for f in numbers:\n",
    "        if \"csv\" in filenames[f]:\n",
    "            file_path_list.append(os.path.join(dirpath, filenames[f]))\n",
    "            dirpaths.append(dirpath)\n",
    "names=filenames\n",
    "\n",
    "for dosya in os.listdir(rootdir):#if \"csv\" in filenames[f]\n",
    "    directory_names.append(dosya)\n",
    "\n",
    "directory_names = [directory for directory in directory_names if \"txt\" not in directory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e6a2d7a-ee59-4390-ba32-0f4803938e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_co2 = StructType([StructField('ts_min_bignt',StringType(),True),\n",
    "                         StructField('co2',FloatType(),True)])\n",
    "\n",
    "schema_humidity = StructType([StructField('tmstmp1',StringType(),True),\n",
    "                              StructField('humidity',FloatType(),True)])\n",
    "\n",
    "schema_light = StructType([StructField('tmstmp2',StringType(),True),\n",
    "                           StructField('light',FloatType(),True)])\n",
    "\n",
    "schema_pir = StructType([StructField('tmstmp3',StringType(),True),\n",
    "                         StructField('pir',FloatType(),True)])\n",
    "                                       \n",
    "schema_temperature = StructType([StructField('tmstmp4',StringType(),True),\n",
    "                                 StructField('temperature',FloatType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c57669-1cfa-431d-a9bd-bbc6aae11c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_schema = [schema_co2, schema_humidity,schema_light,schema_pir, schema_temperature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c9571bd-b64f-4cae-a999-61e8c30bccc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 40.60904335975647 secs -----\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for n in range(0,len(dirpaths),5):\n",
    "    for i in range(len(names)):\n",
    "        df=(spark.read\n",
    "             .option(\"header\", False)\n",
    "             .format(\"csv\")\n",
    "             .schema(list_schema[i])\n",
    "             .load(f\"file://{dirpaths[n]}/{names[i]}\")\n",
    "           )\n",
    "        if i == 0:\n",
    "            df_co2=df.withColumn(\"room\",F.lit((f\"file://{dirpaths[n]}\").split(\"/\")[-1]))\\\n",
    "                    .withColumn(\"event_ts_min\",F.to_timestamp(F.from_unixtime(F.col(\"ts_min_bignt\"),'yyyy-MM-dd HH:mm:ss')))\n",
    "        elif i == 1:\n",
    "            df_humidity =df\n",
    "        elif i == 2:\n",
    "            df_light = df\n",
    "        elif i == 3:\n",
    "            df_pir = df\n",
    "        else:\n",
    "            df_temperature  = df\n",
    "\n",
    "    df_ch=df_co2.join(df_humidity,(df_co2[\"ts_min_bignt\"] == df_humidity[\"tmstmp1\"]),\"inner\")\n",
    "    df_chl = df_ch.join(df_light, (df_ch[\"ts_min_bignt\"] == df_light[\"tmstmp2\"]),\"inner\")\n",
    "    df_chlp = df_chl.join(df_pir, (df_chl[\"ts_min_bignt\"] == df_pir[\"tmstmp3\"]),\"inner\")\n",
    "    df_full= df_chlp.join(df_temperature, (df_chlp[\"ts_min_bignt\"] == df_temperature[\"tmstmp4\"]),\"inner\")\n",
    "\n",
    "    df_full.repartition(1).write\\\n",
    "                      .format(\"csv\")\\\n",
    "                      .mode(\"append\")\\\n",
    "                      .option(\"header\", True)\\\n",
    "                      .save(\"file:///home/train/datasets/sensor_raw_dataset/output/\")\n",
    "\n",
    "print(\"----- %s secs -----\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "703de835-4b06-4d03-a273-be8a79a9f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read_from_csv= spark.read.format(\"csv\").option(\"header\", \"true\").load(\"file:///home/train/datasets/sensor_raw_dataset/output/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58808873-b2ce-4159-87f1-65752056becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read_from_csv=df_read_from_csv.select(\"event_ts_min\",\"ts_min_bignt\",\"room\",\"co2\",\"light\",\"temperature\",\"humidity\",\"pir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b62ed007-54e4-4f12-8734-a895aceddf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135386, 8)\n"
     ]
    }
   ],
   "source": [
    "print((df_read_from_csv.count(), len(df_read_from_csv.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11d25c98-3c0b-4c75-a460-cf57054a6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read_from_csv.repartition(1).write\\\n",
    "                      .format(\"csv\")\\\n",
    "                      .mode(\"append\")\\\n",
    "                      .option(\"header\", True)\\\n",
    "                      .save(\"file:///home/train/datasets/sensor_raw_dataset/datagen_input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c35a1e4f-f217-4b7f-9e53-ba3db38b8f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----+-----+-----+-----------+--------+---+\n",
      "|        event_ts_min|ts_min_bignt|room|  co2|light|temperature|humidity|pir|\n",
      "+--------------------+------------+----+-----+-----+-----------+--------+---+\n",
      "|2013-08-24T02:05:...|  1377299105| 666|437.0|148.0|      24.14|   49.39|0.0|\n",
      "|2013-08-24T02:05:...|  1377299126| 666|442.0|149.0|      24.14|   49.42|0.0|\n",
      "|2013-08-24T02:05:...|  1377299130| 666|442.0|146.0|      24.14|   49.42|0.0|\n",
      "|2013-08-24T02:05:...|  1377299138| 666|442.0|149.0|      24.14|   49.42|0.0|\n",
      "|2013-08-24T02:05:...|  1377299148| 666|448.0|148.0|      24.14|   49.42|0.0|\n",
      "|2013-08-24T02:05:...|  1377299158| 666|449.0|150.0|      24.13|   49.42|0.0|\n",
      "|2013-08-24T02:06:...|  1377299168| 666|445.0|150.0|      24.13|   49.42|0.0|\n",
      "|2013-08-24T02:06:...|  1377299178| 666|445.0|150.0|      24.13|   49.42|0.0|\n",
      "|2013-08-24T02:06:...|  1377299188| 666|437.0|150.0|      24.13|   49.42|0.0|\n",
      "|2013-08-24T02:06:...|  1377299198| 666|437.0|150.0|      24.12|   49.45|0.0|\n",
      "|2013-08-24T02:06:...|  1377299208| 666|456.0|150.0|      24.12|   49.42|0.0|\n",
      "|2013-08-24T02:06:...|  1377299218| 666|448.0|150.0|      24.14|   49.45|0.0|\n",
      "|2013-08-24T02:07:...|  1377299228| 666|446.0|149.0|      24.11|   49.48|0.0|\n",
      "|2013-08-24T02:07:...|  1377299238| 666|453.0|152.0|      24.12|   49.48|0.0|\n",
      "|2013-08-24T02:07:...|  1377299248| 666|447.0|151.0|      24.11|   49.45|0.0|\n",
      "|2013-08-24T02:07:...|  1377299258| 666|446.0|151.0|      24.12|   49.48|0.0|\n",
      "|2013-08-24T02:07:...|  1377299268| 666|456.0|151.0|      24.11|   49.48|0.0|\n",
      "|2013-08-24T02:07:...|  1377299278| 666|458.0|151.0|      24.11|   49.48|0.0|\n",
      "|2013-08-24T02:08:...|  1377299288| 666|456.0|151.0|      24.12|   49.48|0.0|\n",
      "|2013-08-24T02:08:...|  1377299298| 666|447.0|151.0|      24.11|   49.52|0.0|\n",
      "+--------------------+------------+----+-----+-----+-----------+--------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_read_from_csv.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvspark",
   "language": "python",
   "name": "venvspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
